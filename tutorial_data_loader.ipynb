{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading custom CelebA dataset for CC-VAE\n",
    "\n",
    "We explain how the `data_loader` work, and how to adapt the the `setup_data_loader` function to preprocess other datasets for training with `ss_vae.py`\n",
    "\n",
    "**NB:** To startthe training, make sure you have the folder *./data/output* created (otherwise it will throw an error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Any, Callable, List, Optional, Tuple, Union\n",
    "import csv\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import math\n",
    "from utils import dataset_cached as dc\n",
    "from utils import multiclass_dataset_cached as mdc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Understanding CelebA loading process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `root` argument, we have to specify the path to our dataset. For our work, the datasets are in **.data/datasets/** and you can find *CelebA, Mnist or Chexput*.\n",
    "\n",
    "The `setup_data_loader` function returns an dictionary of the form `{mode(string): Dataset}`.\n",
    "\n",
    "It takes many arguments, but only the `root` interests us, as all the others are reusable for any dataset (batch_size, ...).\n",
    "**Each dataset we take as input will be first transformed into a `Dataset` object before setting the data loader.**\n",
    "\n",
    "The Dataset type is inherited from the `CelebA` class, which itself inhertis from the `VisionDataset` class.\n",
    "We have the following inheritance graph:\n",
    "- **CelebaCached <- CelebA <- VisionDataset <- data.Dataset**, where the 3 last classes are built-in scripts that come within the *torchvision* package.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CelebA data\n",
    "\n",
    "The easiest approach to work on subparts of CelebA is to load a Dataset of the right shape and type with the provided `CelebeCached` class, and then randomly discarding data to make it fit the shape we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to make it work:** Authors have set a verification process to avoid downloading infected data. \n",
    "If you want to work with downloaded data (available on the CelebA dataset), you will have to:\n",
    "- Download the code from our github (we modified `CelebACached` class)\n",
    "- In the torchvision package, in the `Celeba.py` file, add the following two lines:\n",
    "1. Add `check_itr = True` as the last argument of the `__init__` method (**line 67**)\n",
    "2. Add `if check_itr:` around the `if self._check_integrity():` block  (**line 82**)\n",
    "\n",
    "That way, we circumvent the obliagtion to run the integrity test, and can correctly load our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original binary classes dataset\n",
      "Splitting Dataset\n",
      "Loading original binary classes dataset\n",
      "Loading original binary classes dataset\n"
     ]
    }
   ],
   "source": [
    "loaders = dc.setup_data_loaders(False, 1, root=\"./data/datasets/celeba\", download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sup': <torch.utils.data.dataloader.DataLoader at 0x7fd2073fd580>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7fd1fe8548e0>,\n",
       " 'valid': <torch.utils.data.dataloader.DataLoader at 0x7fd1e81cc8b0>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Shape of Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datastet Name sup\n",
      "Characteristics Dataset CELEBACached\n",
      "    Number of datapoints: 142770\n",
      "    Root location: ./data/datasets/celeba\n",
      "    Target type: ['attr']\n",
      "    Split: train\n",
      "Elements of dataset are <class 'tuple'> of shape 2:\n",
      "\tElt 1 is a <class 'torch.Tensor'> of shape torch.Size([3, 64, 64])\n",
      "\tElt 2 is a <class 'torch.Tensor'> of shape torch.Size([18])\n",
      "\n",
      "Datastet Name test\n",
      "Characteristics Dataset CELEBACached\n",
      "    Number of datapoints: 19962\n",
      "    Root location: ./data/datasets/celeba\n",
      "    Target type: ['attr']\n",
      "    Split: test\n",
      "Elements of dataset are <class 'tuple'> of shape 2:\n",
      "\tElt 1 is a <class 'torch.Tensor'> of shape torch.Size([3, 64, 64])\n",
      "\tElt 2 is a <class 'torch.Tensor'> of shape torch.Size([18])\n",
      "\n",
      "Datastet Name valid\n",
      "Characteristics Dataset CELEBACached\n",
      "    Number of datapoints: 20000\n",
      "    Root location: ./data/datasets/celeba\n",
      "    Target type: ['attr']\n",
      "    Split: train\n",
      "Elements of dataset are <class 'tuple'> of shape 2:\n",
      "\tElt 1 is a <class 'torch.Tensor'> of shape torch.Size([3, 64, 64])\n",
      "\tElt 2 is a <class 'torch.Tensor'> of shape torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "for l in loaders:\n",
    "    dataloader = loaders[l]\n",
    "    print(f'\\nDatastet Name {l}')\n",
    "    print(f'Characteristics {dataloader.dataset}')\n",
    "\n",
    "    print(f'Elements of dataset are {type(dataloader.dataset[0])} of shape {len(dataloader.dataset[0])}:')\n",
    "    print(f'\\tElt 1 is a {type(dataloader.dataset[0][0])} of shape {(dataloader.dataset[0][0]).shape}')\n",
    "    print(f'\\tElt 2 is a {type(dataloader.dataset[0][1])} of shape {(dataloader.dataset[0][1]).shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning Datasets to train on lower data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, be sure to download the code from the github, as we added the `random_prune_dataloader` in the `dataset_cached.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now prune our dataloaders to get less samples\n",
    "\n",
    "sup_dl = loaders['sup']\n",
    "pruning_ratio= 0.7 # We want to keep 70% of the original dataset\n",
    "\n",
    "pruned_sup_dl = dc.random_prune_dataloader(sup_dl, prune_ratio=pruning_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset of shape 142770\n",
      "Pruned dataset of shape 99939\n"
     ]
    }
   ],
   "source": [
    "print(f'Original dataset of shape {len(sup_dl.dataset)}')\n",
    "print(f'Pruned dataset of shape {len(pruned_sup_dl.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 8, 9, 11, 12, 13, 15, 18, 20, 24, 26, 28, 31, 33, 38, 39]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CelebaCached_dl = pruned_sup_dl.dataset.dataset\n",
    "\n",
    "CelebaCached_dl.sub_label_inds # indexes of celeba labels that are in easy labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CelebaCached_dl.attr_names) # all the attributes are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 0, 0, 1],\n",
       "        ...,\n",
       "        [0, 1, 1,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 1,  ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CelebaCached_dl.train_labels_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2656, 0.2037, 0.1518, 0.2385, 0.1495, 0.2036, 0.1437, 0.0574, 0.0645,\n",
       "        0.3843, 0.4193, 0.8343, 0.0430, 0.0799, 0.4791, 0.3200, 0.0730, 0.7786])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CelebaCached_dl.prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2880],\n",
       "        [2937],\n",
       "        [8692],\n",
       "        ...,\n",
       "        [7391],\n",
       "        [8610],\n",
       "        [2304]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CelebaCached_dl.identity # Attributes in the identity.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000001.jpg',\n",
       " '000002.jpg',\n",
       " '000003.jpg',\n",
       " '000004.jpg',\n",
       " '000005.jpg',\n",
       " '000006.jpg',\n",
       " '000007.jpg',\n",
       " '000008.jpg',\n",
       " '000009.jpg',\n",
       " '000010.jpg',\n",
       " '000011.jpg',\n",
       " '000012.jpg',\n",
       " '000013.jpg',\n",
       " '000014.jpg',\n",
       " '000015.jpg',\n",
       " '000016.jpg',\n",
       " '000017.jpg',\n",
       " '000018.jpg',\n",
       " '000019.jpg',\n",
       " '000020.jpg',\n",
       " '000021.jpg',\n",
       " '000022.jpg',\n",
       " '000023.jpg',\n",
       " '000024.jpg',\n",
       " '000025.jpg',\n",
       " '000026.jpg',\n",
       " '000027.jpg',\n",
       " '000028.jpg',\n",
       " '000029.jpg',\n",
       " '000030.jpg',\n",
       " '000031.jpg',\n",
       " '000032.jpg',\n",
       " '000033.jpg',\n",
       " '000034.jpg',\n",
       " '000035.jpg',\n",
       " '000036.jpg',\n",
       " '000037.jpg',\n",
       " '000038.jpg',\n",
       " '000039.jpg',\n",
       " '000040.jpg',\n",
       " '000041.jpg',\n",
       " '000042.jpg',\n",
       " '000043.jpg',\n",
       " '000044.jpg',\n",
       " '000045.jpg',\n",
       " '000046.jpg',\n",
       " '000047.jpg',\n",
       " '000048.jpg',\n",
       " '000049.jpg',\n",
       " '000050.jpg',\n",
       " '000051.jpg',\n",
       " '000052.jpg',\n",
       " '000053.jpg',\n",
       " '000054.jpg',\n",
       " '000055.jpg',\n",
       " '000056.jpg',\n",
       " '000057.jpg',\n",
       " '000058.jpg',\n",
       " '000059.jpg',\n",
       " '000060.jpg',\n",
       " '000061.jpg',\n",
       " '000062.jpg',\n",
       " '000063.jpg',\n",
       " '000064.jpg',\n",
       " '000065.jpg',\n",
       " '000066.jpg',\n",
       " '000067.jpg',\n",
       " '000068.jpg',\n",
       " '000069.jpg',\n",
       " '000070.jpg',\n",
       " '000071.jpg',\n",
       " '000072.jpg',\n",
       " '000073.jpg',\n",
       " '000074.jpg',\n",
       " '000075.jpg',\n",
       " '000076.jpg',\n",
       " '000077.jpg',\n",
       " '000078.jpg',\n",
       " '000079.jpg',\n",
       " '000080.jpg',\n",
       " '000081.jpg',\n",
       " '000082.jpg',\n",
       " '000083.jpg',\n",
       " '000084.jpg',\n",
       " '000085.jpg',\n",
       " '000086.jpg',\n",
       " '000087.jpg',\n",
       " '000088.jpg',\n",
       " '000089.jpg',\n",
       " '000090.jpg',\n",
       " '000091.jpg',\n",
       " '000092.jpg',\n",
       " '000093.jpg',\n",
       " '000094.jpg',\n",
       " '000095.jpg',\n",
       " '000096.jpg',\n",
       " '000097.jpg',\n",
       " '000098.jpg',\n",
       " '000099.jpg',\n",
       " '000100.jpg',\n",
       " '000101.jpg',\n",
       " '000102.jpg',\n",
       " '000103.jpg',\n",
       " '000104.jpg',\n",
       " '000105.jpg',\n",
       " '000106.jpg',\n",
       " '000107.jpg',\n",
       " '000108.jpg',\n",
       " '000109.jpg',\n",
       " '000110.jpg',\n",
       " '000111.jpg',\n",
       " '000112.jpg',\n",
       " '000113.jpg',\n",
       " '000114.jpg',\n",
       " '000115.jpg',\n",
       " '000116.jpg',\n",
       " '000117.jpg',\n",
       " '000118.jpg',\n",
       " '000119.jpg',\n",
       " '000120.jpg',\n",
       " '000121.jpg',\n",
       " '000122.jpg',\n",
       " '000123.jpg',\n",
       " '000124.jpg',\n",
       " '000125.jpg',\n",
       " '000126.jpg',\n",
       " '000127.jpg',\n",
       " '000128.jpg',\n",
       " '000129.jpg',\n",
       " '000130.jpg',\n",
       " '000131.jpg',\n",
       " '000132.jpg',\n",
       " '000133.jpg',\n",
       " '000134.jpg',\n",
       " '000135.jpg',\n",
       " '000136.jpg',\n",
       " '000137.jpg',\n",
       " '000138.jpg',\n",
       " '000139.jpg',\n",
       " '000140.jpg',\n",
       " '000141.jpg',\n",
       " '000142.jpg',\n",
       " '000143.jpg',\n",
       " '000144.jpg',\n",
       " '000145.jpg',\n",
       " '000146.jpg',\n",
       " '000147.jpg',\n",
       " '000148.jpg',\n",
       " '000149.jpg',\n",
       " '000150.jpg',\n",
       " '000151.jpg',\n",
       " '000152.jpg',\n",
       " '000153.jpg',\n",
       " '000154.jpg',\n",
       " '000155.jpg',\n",
       " '000156.jpg',\n",
       " '000157.jpg',\n",
       " '000158.jpg',\n",
       " '000159.jpg',\n",
       " '000160.jpg',\n",
       " '000161.jpg',\n",
       " '000162.jpg',\n",
       " '000163.jpg',\n",
       " '000164.jpg',\n",
       " '000165.jpg',\n",
       " '000166.jpg',\n",
       " '000167.jpg',\n",
       " '000168.jpg',\n",
       " '000169.jpg',\n",
       " '000170.jpg',\n",
       " '000171.jpg',\n",
       " '000172.jpg',\n",
       " '000173.jpg',\n",
       " '000174.jpg',\n",
       " '000175.jpg',\n",
       " '000176.jpg',\n",
       " '000177.jpg',\n",
       " '000178.jpg',\n",
       " '000179.jpg',\n",
       " '000180.jpg',\n",
       " '000181.jpg',\n",
       " '000182.jpg',\n",
       " '000183.jpg',\n",
       " '000184.jpg',\n",
       " '000185.jpg',\n",
       " '000186.jpg',\n",
       " '000187.jpg',\n",
       " '000188.jpg',\n",
       " '000189.jpg',\n",
       " '000190.jpg',\n",
       " '000191.jpg',\n",
       " '000192.jpg',\n",
       " '000193.jpg',\n",
       " '000194.jpg',\n",
       " '000195.jpg',\n",
       " '000196.jpg',\n",
       " '000197.jpg',\n",
       " '000198.jpg',\n",
       " '000199.jpg',\n",
       " '000200.jpg',\n",
       " '000201.jpg',\n",
       " '000202.jpg',\n",
       " '000203.jpg',\n",
       " '000204.jpg',\n",
       " '000205.jpg',\n",
       " '000206.jpg',\n",
       " '000207.jpg',\n",
       " '000208.jpg',\n",
       " '000209.jpg',\n",
       " '000210.jpg',\n",
       " '000211.jpg',\n",
       " '000212.jpg',\n",
       " '000213.jpg',\n",
       " '000214.jpg',\n",
       " '000215.jpg',\n",
       " '000216.jpg',\n",
       " '000217.jpg',\n",
       " '000218.jpg',\n",
       " '000219.jpg',\n",
       " '000220.jpg',\n",
       " '000221.jpg',\n",
       " '000222.jpg',\n",
       " '000223.jpg',\n",
       " '000224.jpg',\n",
       " '000225.jpg',\n",
       " '000226.jpg',\n",
       " '000227.jpg',\n",
       " '000228.jpg',\n",
       " '000229.jpg',\n",
       " '000230.jpg',\n",
       " '000231.jpg',\n",
       " '000232.jpg',\n",
       " '000233.jpg',\n",
       " '000234.jpg',\n",
       " '000235.jpg',\n",
       " '000236.jpg',\n",
       " '000237.jpg',\n",
       " '000238.jpg',\n",
       " '000239.jpg',\n",
       " '000240.jpg',\n",
       " '000241.jpg',\n",
       " '000242.jpg',\n",
       " '000243.jpg',\n",
       " '000244.jpg',\n",
       " '000245.jpg',\n",
       " '000246.jpg',\n",
       " '000247.jpg',\n",
       " '000248.jpg',\n",
       " '000249.jpg',\n",
       " '000250.jpg',\n",
       " '000251.jpg',\n",
       " '000252.jpg',\n",
       " '000253.jpg',\n",
       " '000254.jpg',\n",
       " '000255.jpg',\n",
       " '000256.jpg',\n",
       " '000257.jpg',\n",
       " '000258.jpg',\n",
       " '000259.jpg',\n",
       " '000260.jpg',\n",
       " '000261.jpg',\n",
       " '000262.jpg',\n",
       " '000263.jpg',\n",
       " '000264.jpg',\n",
       " '000265.jpg',\n",
       " '000266.jpg',\n",
       " '000267.jpg',\n",
       " '000268.jpg',\n",
       " '000269.jpg',\n",
       " '000270.jpg',\n",
       " '000271.jpg',\n",
       " '000272.jpg',\n",
       " '000273.jpg',\n",
       " '000274.jpg',\n",
       " '000275.jpg',\n",
       " '000276.jpg',\n",
       " '000277.jpg',\n",
       " '000278.jpg',\n",
       " '000279.jpg',\n",
       " '000280.jpg',\n",
       " '000281.jpg',\n",
       " '000282.jpg',\n",
       " '000283.jpg',\n",
       " '000284.jpg',\n",
       " '000285.jpg',\n",
       " '000286.jpg',\n",
       " '000287.jpg',\n",
       " '000288.jpg',\n",
       " '000289.jpg',\n",
       " '000290.jpg',\n",
       " '000291.jpg',\n",
       " '000292.jpg',\n",
       " '000293.jpg',\n",
       " '000294.jpg',\n",
       " '000295.jpg',\n",
       " '000296.jpg',\n",
       " '000297.jpg',\n",
       " '000298.jpg',\n",
       " '000299.jpg',\n",
       " '000300.jpg',\n",
       " '000301.jpg',\n",
       " '000302.jpg',\n",
       " '000303.jpg',\n",
       " '000304.jpg',\n",
       " '000305.jpg',\n",
       " '000306.jpg',\n",
       " '000307.jpg',\n",
       " '000308.jpg',\n",
       " '000309.jpg',\n",
       " '000310.jpg',\n",
       " '000311.jpg',\n",
       " '000312.jpg',\n",
       " '000313.jpg',\n",
       " '000314.jpg',\n",
       " '000315.jpg',\n",
       " '000316.jpg',\n",
       " '000317.jpg',\n",
       " '000318.jpg',\n",
       " '000319.jpg',\n",
       " '000320.jpg',\n",
       " '000321.jpg',\n",
       " '000322.jpg',\n",
       " '000323.jpg',\n",
       " '000324.jpg',\n",
       " '000325.jpg',\n",
       " '000326.jpg',\n",
       " '000327.jpg',\n",
       " '000328.jpg',\n",
       " '000329.jpg',\n",
       " '000330.jpg',\n",
       " '000331.jpg',\n",
       " '000332.jpg',\n",
       " '000333.jpg',\n",
       " '000334.jpg',\n",
       " '000335.jpg',\n",
       " '000336.jpg',\n",
       " '000337.jpg',\n",
       " '000338.jpg',\n",
       " '000339.jpg',\n",
       " '000340.jpg',\n",
       " '000341.jpg',\n",
       " '000342.jpg',\n",
       " '000343.jpg',\n",
       " '000344.jpg',\n",
       " '000345.jpg',\n",
       " '000346.jpg',\n",
       " '000347.jpg',\n",
       " '000348.jpg',\n",
       " '000349.jpg',\n",
       " '000350.jpg',\n",
       " '000351.jpg',\n",
       " '000352.jpg',\n",
       " '000353.jpg',\n",
       " '000354.jpg',\n",
       " '000355.jpg',\n",
       " '000356.jpg',\n",
       " '000357.jpg',\n",
       " '000358.jpg',\n",
       " '000359.jpg',\n",
       " '000360.jpg',\n",
       " '000361.jpg',\n",
       " '000362.jpg',\n",
       " '000363.jpg',\n",
       " '000364.jpg',\n",
       " '000365.jpg',\n",
       " '000366.jpg',\n",
       " '000367.jpg',\n",
       " '000368.jpg',\n",
       " '000369.jpg',\n",
       " '000370.jpg',\n",
       " '000371.jpg',\n",
       " '000372.jpg',\n",
       " '000373.jpg',\n",
       " '000374.jpg',\n",
       " '000375.jpg',\n",
       " '000376.jpg',\n",
       " '000377.jpg',\n",
       " '000378.jpg',\n",
       " '000379.jpg',\n",
       " '000380.jpg',\n",
       " '000381.jpg',\n",
       " '000382.jpg',\n",
       " '000383.jpg',\n",
       " '000384.jpg',\n",
       " '000385.jpg',\n",
       " '000386.jpg',\n",
       " '000387.jpg',\n",
       " '000388.jpg',\n",
       " '000389.jpg',\n",
       " '000390.jpg',\n",
       " '000391.jpg',\n",
       " '000392.jpg',\n",
       " '000393.jpg',\n",
       " '000394.jpg',\n",
       " '000395.jpg',\n",
       " '000396.jpg',\n",
       " '000397.jpg',\n",
       " '000398.jpg',\n",
       " '000399.jpg',\n",
       " '000400.jpg',\n",
       " '000401.jpg',\n",
       " '000402.jpg',\n",
       " '000403.jpg',\n",
       " '000404.jpg',\n",
       " '000405.jpg',\n",
       " '000406.jpg',\n",
       " '000407.jpg',\n",
       " '000408.jpg',\n",
       " '000409.jpg',\n",
       " '000410.jpg',\n",
       " '000411.jpg',\n",
       " '000412.jpg',\n",
       " '000413.jpg',\n",
       " '000414.jpg',\n",
       " '000415.jpg',\n",
       " '000416.jpg',\n",
       " '000417.jpg',\n",
       " '000418.jpg',\n",
       " '000419.jpg',\n",
       " '000420.jpg',\n",
       " '000421.jpg',\n",
       " '000422.jpg',\n",
       " '000423.jpg',\n",
       " '000424.jpg',\n",
       " '000425.jpg',\n",
       " '000426.jpg',\n",
       " '000427.jpg',\n",
       " '000428.jpg',\n",
       " '000429.jpg',\n",
       " '000430.jpg',\n",
       " '000431.jpg',\n",
       " '000432.jpg',\n",
       " '000433.jpg',\n",
       " '000434.jpg',\n",
       " '000435.jpg',\n",
       " '000436.jpg',\n",
       " '000437.jpg',\n",
       " '000438.jpg',\n",
       " '000439.jpg',\n",
       " '000440.jpg',\n",
       " '000441.jpg',\n",
       " '000442.jpg',\n",
       " '000443.jpg',\n",
       " '000444.jpg',\n",
       " '000445.jpg',\n",
       " '000446.jpg',\n",
       " '000447.jpg',\n",
       " '000448.jpg',\n",
       " '000449.jpg',\n",
       " '000450.jpg',\n",
       " '000451.jpg',\n",
       " '000452.jpg',\n",
       " '000453.jpg',\n",
       " '000454.jpg',\n",
       " '000455.jpg',\n",
       " '000456.jpg',\n",
       " '000457.jpg',\n",
       " '000458.jpg',\n",
       " '000459.jpg',\n",
       " '000460.jpg',\n",
       " '000461.jpg',\n",
       " '000462.jpg',\n",
       " '000463.jpg',\n",
       " '000464.jpg',\n",
       " '000465.jpg',\n",
       " '000466.jpg',\n",
       " '000467.jpg',\n",
       " '000468.jpg',\n",
       " '000469.jpg',\n",
       " '000470.jpg',\n",
       " '000471.jpg',\n",
       " '000472.jpg',\n",
       " '000473.jpg',\n",
       " '000474.jpg',\n",
       " '000475.jpg',\n",
       " '000476.jpg',\n",
       " '000477.jpg',\n",
       " '000478.jpg',\n",
       " '000479.jpg',\n",
       " '000480.jpg',\n",
       " '000481.jpg',\n",
       " '000482.jpg',\n",
       " '000483.jpg',\n",
       " '000484.jpg',\n",
       " '000485.jpg',\n",
       " '000486.jpg',\n",
       " '000487.jpg',\n",
       " '000488.jpg',\n",
       " '000489.jpg',\n",
       " '000490.jpg',\n",
       " '000491.jpg',\n",
       " '000492.jpg',\n",
       " '000493.jpg',\n",
       " '000494.jpg',\n",
       " '000495.jpg',\n",
       " '000496.jpg',\n",
       " '000497.jpg',\n",
       " '000498.jpg',\n",
       " '000499.jpg',\n",
       " '000500.jpg',\n",
       " '000501.jpg',\n",
       " '000502.jpg',\n",
       " '000503.jpg',\n",
       " '000504.jpg',\n",
       " '000505.jpg',\n",
       " '000506.jpg',\n",
       " '000507.jpg',\n",
       " '000508.jpg',\n",
       " '000509.jpg',\n",
       " '000510.jpg',\n",
       " '000511.jpg',\n",
       " '000512.jpg',\n",
       " '000513.jpg',\n",
       " '000514.jpg',\n",
       " '000515.jpg',\n",
       " '000516.jpg',\n",
       " '000517.jpg',\n",
       " '000518.jpg',\n",
       " '000519.jpg',\n",
       " '000520.jpg',\n",
       " '000521.jpg',\n",
       " '000522.jpg',\n",
       " '000523.jpg',\n",
       " '000524.jpg',\n",
       " '000525.jpg',\n",
       " '000526.jpg',\n",
       " '000527.jpg',\n",
       " '000528.jpg',\n",
       " '000529.jpg',\n",
       " '000530.jpg',\n",
       " '000531.jpg',\n",
       " '000532.jpg',\n",
       " '000533.jpg',\n",
       " '000534.jpg',\n",
       " '000535.jpg',\n",
       " '000536.jpg',\n",
       " '000537.jpg',\n",
       " '000538.jpg',\n",
       " '000539.jpg',\n",
       " '000540.jpg',\n",
       " '000541.jpg',\n",
       " '000542.jpg',\n",
       " '000543.jpg',\n",
       " '000544.jpg',\n",
       " '000545.jpg',\n",
       " '000546.jpg',\n",
       " '000547.jpg',\n",
       " '000548.jpg',\n",
       " '000549.jpg',\n",
       " '000550.jpg',\n",
       " '000551.jpg',\n",
       " '000552.jpg',\n",
       " '000553.jpg',\n",
       " '000554.jpg',\n",
       " '000555.jpg',\n",
       " '000556.jpg',\n",
       " '000557.jpg',\n",
       " '000558.jpg',\n",
       " '000559.jpg',\n",
       " '000560.jpg',\n",
       " '000561.jpg',\n",
       " '000562.jpg',\n",
       " '000563.jpg',\n",
       " '000564.jpg',\n",
       " '000565.jpg',\n",
       " '000566.jpg',\n",
       " '000567.jpg',\n",
       " '000568.jpg',\n",
       " '000569.jpg',\n",
       " '000570.jpg',\n",
       " '000571.jpg',\n",
       " '000572.jpg',\n",
       " '000573.jpg',\n",
       " '000574.jpg',\n",
       " '000575.jpg',\n",
       " '000576.jpg',\n",
       " '000577.jpg',\n",
       " '000578.jpg',\n",
       " '000579.jpg',\n",
       " '000580.jpg',\n",
       " '000581.jpg',\n",
       " '000582.jpg',\n",
       " '000583.jpg',\n",
       " '000584.jpg',\n",
       " '000585.jpg',\n",
       " '000586.jpg',\n",
       " '000587.jpg',\n",
       " '000588.jpg',\n",
       " '000589.jpg',\n",
       " '000590.jpg',\n",
       " '000591.jpg',\n",
       " '000592.jpg',\n",
       " '000593.jpg',\n",
       " '000594.jpg',\n",
       " '000595.jpg',\n",
       " '000596.jpg',\n",
       " '000597.jpg',\n",
       " '000598.jpg',\n",
       " '000599.jpg',\n",
       " '000600.jpg',\n",
       " '000601.jpg',\n",
       " '000602.jpg',\n",
       " '000603.jpg',\n",
       " '000604.jpg',\n",
       " '000605.jpg',\n",
       " '000606.jpg',\n",
       " '000607.jpg',\n",
       " '000608.jpg',\n",
       " '000609.jpg',\n",
       " '000610.jpg',\n",
       " '000611.jpg',\n",
       " '000612.jpg',\n",
       " '000613.jpg',\n",
       " '000614.jpg',\n",
       " '000615.jpg',\n",
       " '000616.jpg',\n",
       " '000617.jpg',\n",
       " '000618.jpg',\n",
       " '000619.jpg',\n",
       " '000620.jpg',\n",
       " '000621.jpg',\n",
       " '000622.jpg',\n",
       " '000623.jpg',\n",
       " '000624.jpg',\n",
       " '000625.jpg',\n",
       " '000626.jpg',\n",
       " '000627.jpg',\n",
       " '000628.jpg',\n",
       " '000629.jpg',\n",
       " '000630.jpg',\n",
       " '000631.jpg',\n",
       " '000632.jpg',\n",
       " '000633.jpg',\n",
       " '000634.jpg',\n",
       " '000635.jpg',\n",
       " '000636.jpg',\n",
       " '000637.jpg',\n",
       " '000638.jpg',\n",
       " '000639.jpg',\n",
       " '000640.jpg',\n",
       " '000641.jpg',\n",
       " '000642.jpg',\n",
       " '000643.jpg',\n",
       " '000644.jpg',\n",
       " '000645.jpg',\n",
       " '000646.jpg',\n",
       " '000647.jpg',\n",
       " '000648.jpg',\n",
       " '000649.jpg',\n",
       " '000650.jpg',\n",
       " '000651.jpg',\n",
       " '000652.jpg',\n",
       " '000653.jpg',\n",
       " '000654.jpg',\n",
       " '000655.jpg',\n",
       " '000656.jpg',\n",
       " '000657.jpg',\n",
       " '000658.jpg',\n",
       " '000659.jpg',\n",
       " '000660.jpg',\n",
       " '000661.jpg',\n",
       " '000662.jpg',\n",
       " '000663.jpg',\n",
       " '000664.jpg',\n",
       " '000665.jpg',\n",
       " '000666.jpg',\n",
       " '000667.jpg',\n",
       " '000668.jpg',\n",
       " '000669.jpg',\n",
       " '000670.jpg',\n",
       " '000671.jpg',\n",
       " '000672.jpg',\n",
       " '000673.jpg',\n",
       " '000674.jpg',\n",
       " '000675.jpg',\n",
       " '000676.jpg',\n",
       " '000677.jpg',\n",
       " '000678.jpg',\n",
       " '000679.jpg',\n",
       " '000680.jpg',\n",
       " '000681.jpg',\n",
       " '000682.jpg',\n",
       " '000683.jpg',\n",
       " '000684.jpg',\n",
       " '000685.jpg',\n",
       " '000686.jpg',\n",
       " '000687.jpg',\n",
       " '000688.jpg',\n",
       " '000689.jpg',\n",
       " '000690.jpg',\n",
       " '000691.jpg',\n",
       " '000692.jpg',\n",
       " '000693.jpg',\n",
       " '000694.jpg',\n",
       " '000695.jpg',\n",
       " '000696.jpg',\n",
       " '000697.jpg',\n",
       " '000698.jpg',\n",
       " '000699.jpg',\n",
       " '000700.jpg',\n",
       " '000701.jpg',\n",
       " '000702.jpg',\n",
       " '000703.jpg',\n",
       " '000704.jpg',\n",
       " '000705.jpg',\n",
       " '000706.jpg',\n",
       " '000707.jpg',\n",
       " '000708.jpg',\n",
       " '000709.jpg',\n",
       " '000710.jpg',\n",
       " '000711.jpg',\n",
       " '000712.jpg',\n",
       " '000713.jpg',\n",
       " '000714.jpg',\n",
       " '000715.jpg',\n",
       " '000716.jpg',\n",
       " '000717.jpg',\n",
       " '000718.jpg',\n",
       " '000719.jpg',\n",
       " '000720.jpg',\n",
       " '000721.jpg',\n",
       " '000722.jpg',\n",
       " '000723.jpg',\n",
       " '000724.jpg',\n",
       " '000725.jpg',\n",
       " '000726.jpg',\n",
       " '000727.jpg',\n",
       " '000728.jpg',\n",
       " '000729.jpg',\n",
       " '000730.jpg',\n",
       " '000731.jpg',\n",
       " '000732.jpg',\n",
       " '000733.jpg',\n",
       " '000734.jpg',\n",
       " '000735.jpg',\n",
       " '000736.jpg',\n",
       " '000737.jpg',\n",
       " '000738.jpg',\n",
       " '000739.jpg',\n",
       " '000740.jpg',\n",
       " '000741.jpg',\n",
       " '000742.jpg',\n",
       " '000743.jpg',\n",
       " '000744.jpg',\n",
       " '000745.jpg',\n",
       " '000746.jpg',\n",
       " '000747.jpg',\n",
       " '000748.jpg',\n",
       " '000749.jpg',\n",
       " '000750.jpg',\n",
       " '000751.jpg',\n",
       " '000752.jpg',\n",
       " '000753.jpg',\n",
       " '000754.jpg',\n",
       " '000755.jpg',\n",
       " '000756.jpg',\n",
       " '000757.jpg',\n",
       " '000758.jpg',\n",
       " '000759.jpg',\n",
       " '000760.jpg',\n",
       " '000761.jpg',\n",
       " '000762.jpg',\n",
       " '000763.jpg',\n",
       " '000764.jpg',\n",
       " '000765.jpg',\n",
       " '000766.jpg',\n",
       " '000767.jpg',\n",
       " '000768.jpg',\n",
       " '000769.jpg',\n",
       " '000770.jpg',\n",
       " '000771.jpg',\n",
       " '000772.jpg',\n",
       " '000773.jpg',\n",
       " '000774.jpg',\n",
       " '000775.jpg',\n",
       " '000776.jpg',\n",
       " '000777.jpg',\n",
       " '000778.jpg',\n",
       " '000779.jpg',\n",
       " '000780.jpg',\n",
       " '000781.jpg',\n",
       " '000782.jpg',\n",
       " '000783.jpg',\n",
       " '000784.jpg',\n",
       " '000785.jpg',\n",
       " '000786.jpg',\n",
       " '000787.jpg',\n",
       " '000788.jpg',\n",
       " '000789.jpg',\n",
       " '000790.jpg',\n",
       " '000791.jpg',\n",
       " '000792.jpg',\n",
       " '000793.jpg',\n",
       " '000794.jpg',\n",
       " '000795.jpg',\n",
       " '000796.jpg',\n",
       " '000797.jpg',\n",
       " '000798.jpg',\n",
       " '000799.jpg',\n",
       " '000800.jpg',\n",
       " '000801.jpg',\n",
       " '000802.jpg',\n",
       " '000803.jpg',\n",
       " '000804.jpg',\n",
       " '000805.jpg',\n",
       " '000806.jpg',\n",
       " '000807.jpg',\n",
       " '000808.jpg',\n",
       " '000809.jpg',\n",
       " '000810.jpg',\n",
       " '000811.jpg',\n",
       " '000812.jpg',\n",
       " '000813.jpg',\n",
       " '000814.jpg',\n",
       " '000815.jpg',\n",
       " '000816.jpg',\n",
       " '000817.jpg',\n",
       " '000818.jpg',\n",
       " '000819.jpg',\n",
       " '000820.jpg',\n",
       " '000821.jpg',\n",
       " '000822.jpg',\n",
       " '000823.jpg',\n",
       " '000824.jpg',\n",
       " '000825.jpg',\n",
       " '000826.jpg',\n",
       " '000827.jpg',\n",
       " '000828.jpg',\n",
       " '000829.jpg',\n",
       " '000830.jpg',\n",
       " '000831.jpg',\n",
       " '000832.jpg',\n",
       " '000833.jpg',\n",
       " '000834.jpg',\n",
       " '000835.jpg',\n",
       " '000836.jpg',\n",
       " '000837.jpg',\n",
       " '000838.jpg',\n",
       " '000839.jpg',\n",
       " '000840.jpg',\n",
       " '000841.jpg',\n",
       " '000842.jpg',\n",
       " '000843.jpg',\n",
       " '000844.jpg',\n",
       " '000845.jpg',\n",
       " '000846.jpg',\n",
       " '000847.jpg',\n",
       " '000848.jpg',\n",
       " '000849.jpg',\n",
       " '000850.jpg',\n",
       " '000851.jpg',\n",
       " '000852.jpg',\n",
       " '000853.jpg',\n",
       " '000854.jpg',\n",
       " '000855.jpg',\n",
       " '000856.jpg',\n",
       " '000857.jpg',\n",
       " '000858.jpg',\n",
       " '000859.jpg',\n",
       " '000860.jpg',\n",
       " '000861.jpg',\n",
       " '000862.jpg',\n",
       " '000863.jpg',\n",
       " '000864.jpg',\n",
       " '000865.jpg',\n",
       " '000866.jpg',\n",
       " '000867.jpg',\n",
       " '000868.jpg',\n",
       " '000869.jpg',\n",
       " '000870.jpg',\n",
       " '000871.jpg',\n",
       " '000872.jpg',\n",
       " '000873.jpg',\n",
       " '000874.jpg',\n",
       " '000875.jpg',\n",
       " '000876.jpg',\n",
       " '000877.jpg',\n",
       " '000878.jpg',\n",
       " '000879.jpg',\n",
       " '000880.jpg',\n",
       " '000881.jpg',\n",
       " '000882.jpg',\n",
       " '000883.jpg',\n",
       " '000884.jpg',\n",
       " '000885.jpg',\n",
       " '000886.jpg',\n",
       " '000887.jpg',\n",
       " '000888.jpg',\n",
       " '000889.jpg',\n",
       " '000890.jpg',\n",
       " '000891.jpg',\n",
       " '000892.jpg',\n",
       " '000893.jpg',\n",
       " '000894.jpg',\n",
       " '000895.jpg',\n",
       " '000896.jpg',\n",
       " '000897.jpg',\n",
       " '000898.jpg',\n",
       " '000899.jpg',\n",
       " '000900.jpg',\n",
       " '000901.jpg',\n",
       " '000902.jpg',\n",
       " '000903.jpg',\n",
       " '000904.jpg',\n",
       " '000905.jpg',\n",
       " '000906.jpg',\n",
       " '000907.jpg',\n",
       " '000908.jpg',\n",
       " '000909.jpg',\n",
       " '000910.jpg',\n",
       " '000911.jpg',\n",
       " '000912.jpg',\n",
       " '000913.jpg',\n",
       " '000914.jpg',\n",
       " '000915.jpg',\n",
       " '000916.jpg',\n",
       " '000917.jpg',\n",
       " '000918.jpg',\n",
       " '000919.jpg',\n",
       " '000920.jpg',\n",
       " '000921.jpg',\n",
       " '000922.jpg',\n",
       " '000923.jpg',\n",
       " '000924.jpg',\n",
       " '000925.jpg',\n",
       " '000926.jpg',\n",
       " '000927.jpg',\n",
       " '000928.jpg',\n",
       " '000929.jpg',\n",
       " '000930.jpg',\n",
       " '000931.jpg',\n",
       " '000932.jpg',\n",
       " '000933.jpg',\n",
       " '000934.jpg',\n",
       " '000935.jpg',\n",
       " '000936.jpg',\n",
       " '000937.jpg',\n",
       " '000938.jpg',\n",
       " '000939.jpg',\n",
       " '000940.jpg',\n",
       " '000941.jpg',\n",
       " '000942.jpg',\n",
       " '000943.jpg',\n",
       " '000944.jpg',\n",
       " '000945.jpg',\n",
       " '000946.jpg',\n",
       " '000947.jpg',\n",
       " '000948.jpg',\n",
       " '000949.jpg',\n",
       " '000950.jpg',\n",
       " '000951.jpg',\n",
       " '000952.jpg',\n",
       " '000953.jpg',\n",
       " '000954.jpg',\n",
       " '000955.jpg',\n",
       " '000956.jpg',\n",
       " '000957.jpg',\n",
       " '000958.jpg',\n",
       " '000959.jpg',\n",
       " '000960.jpg',\n",
       " '000961.jpg',\n",
       " '000962.jpg',\n",
       " '000963.jpg',\n",
       " '000964.jpg',\n",
       " '000965.jpg',\n",
       " '000966.jpg',\n",
       " '000967.jpg',\n",
       " '000968.jpg',\n",
       " '000969.jpg',\n",
       " '000970.jpg',\n",
       " '000971.jpg',\n",
       " '000972.jpg',\n",
       " '000973.jpg',\n",
       " '000974.jpg',\n",
       " '000975.jpg',\n",
       " '000976.jpg',\n",
       " '000977.jpg',\n",
       " '000978.jpg',\n",
       " '000979.jpg',\n",
       " '000980.jpg',\n",
       " '000981.jpg',\n",
       " '000982.jpg',\n",
       " '000983.jpg',\n",
       " '000984.jpg',\n",
       " '000985.jpg',\n",
       " '000986.jpg',\n",
       " '000987.jpg',\n",
       " '000988.jpg',\n",
       " '000989.jpg',\n",
       " '000990.jpg',\n",
       " '000991.jpg',\n",
       " '000992.jpg',\n",
       " '000993.jpg',\n",
       " '000994.jpg',\n",
       " '000995.jpg',\n",
       " '000996.jpg',\n",
       " '000997.jpg',\n",
       " '000998.jpg',\n",
       " '000999.jpg',\n",
       " '001000.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CelebaCached_dl.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Training in a Multi-label fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we do no have binary labels (attractive or not, brown hair or not, ...), but rather a label that can be classified in multiple ouput (hair type: brown, blond, black, bald).\n",
    "Thus, the prior we have is $\\frac{1}{n_{classes}}$. \n",
    "\n",
    "In `CelebaCached`, the prior are not values anymore (probabilities between 0 and 1: at the beginning the mean over all the datapoints), but rather a `Categorical` distribution that compute probabilities for each of the class $c \\in [1: n_{classes}]$.\n",
    "\n",
    "To have thid part runing, you have to do the following changes:\n",
    "- Use *multiclass_dataset_cached.py* instead of *dataset_cached.py*\n",
    "- Change the *celeba.py* file of the torchvision library (`__init__` function, `_load_csv` function (you can find it below))\n",
    "\n",
    "**Note that even if this is adapted for multiclass, it should work also on the originial, binary dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **IMPORTANT:** \n",
    "- The Mutli-class labels must be named in the dataset (*.txt* files) 'classname_MULTI' (otherwise, will be transformed as if they were binary classes)\n",
    "- Again, don't forget to pass the `multi_class = True` keyword argument in the `setup_data_loader` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\_\\_init\\_\\_ function **COPY THIS**:\n",
    "```\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        split: str = \"train\",\n",
    "        target_type: Union[List[str], str] = \"attr\",\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        download: bool = False,\n",
    "        check_itr = True,\n",
    "        multi_class = False\n",
    "    ) -> None:\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "        self.split = split\n",
    "        if isinstance(target_type, list):\n",
    "            self.target_type = target_type\n",
    "        else:\n",
    "            self.target_type = [target_type]\n",
    "\n",
    "        if not self.target_type and self.target_transform is not None:\n",
    "            raise RuntimeError(\"target_transform is specified but target_type is empty\")\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if(check_itr):\n",
    "            if not self._check_integrity():\n",
    "                raise RuntimeError(\"Dataset not found or corrupted. You can use download=True to download it\")\n",
    "\n",
    "        split_map = {\n",
    "            \"train\": 0,\n",
    "            \"valid\": 1,\n",
    "            \"test\": 2,\n",
    "            \"all\": None,\n",
    "        }\n",
    "        split_ = split_map[verify_str_arg(split.lower(), \"split\", (\"train\", \"valid\", \"test\", \"all\"))]\n",
    "\n",
    "        if(multi_class):\n",
    "            print('Loading MULTI_CLASS dataset')\n",
    "            attr = self._load_csv(\"list_attr_multiclass_celeba.txt\", header=1)\n",
    "            splits = self._load_csv(\"list_eval_partition_multiclass.txt\")\n",
    "            identity = self._load_csv(\"identity_multiclass_CelebA.txt\")\n",
    "            bbox = self._load_csv(\"list_bbox_multiclass_celeba.txt\", header=1)\n",
    "            landmarks_align = self._load_csv(\"list_landmarks_align_multiclass_celeba.txt\", header=1)\n",
    "\n",
    "        else:\n",
    "            print('Loading original binary classes dataset')\n",
    "            attr = self._load_csv(\"list_attr_celeba.txt\", header=1)\n",
    "            splits = self._load_csv(\"list_eval_partition.txt\")\n",
    "            identity = self._load_csv(\"identity_CelebA.txt\")\n",
    "            bbox = self._load_csv(\"list_bbox_celeba.txt\", header=1)\n",
    "            landmarks_align = self._load_csv(\"list_landmarks_align_celeba.txt\", header=1)\n",
    "\n",
    "        mask = slice(None) if split_ is None else (splits.data == split_).squeeze()\n",
    "\n",
    "        if mask == slice(None):  # if split == \"all\"\n",
    "            self.filename = splits.index\n",
    "        else:\n",
    "            self.filename = [splits.index[i] for i in torch.squeeze(torch.nonzero(mask))]\n",
    "        self.identity = identity.data[mask]\n",
    "        self.bbox = bbox.data[mask]\n",
    "        self.landmarks_align = landmarks_align.data[mask]\n",
    "        self.attr = attr.data[mask]\n",
    "        self.attr_names = attr.header\n",
    "        # map from {-1, 1} to {0, 1} if not multi-class label\n",
    "        for i, lab in enumerate(self.attr_names):\n",
    "            if('MULTI' not in lab): # dealing with multi class labels\n",
    "                self.attr[:, i] = torch.div(self.attr[:, i] + 1, 2, rounding_mode=\"floor\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show how to access the priors of the Categorical Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CELEBA_MULTI_LABELS = {'Hair': 5} # Multi-mabel: has 5 possible rankings\n",
    "\n",
    "prior = []\n",
    "dict_index_class = {}\n",
    "i=0\n",
    "\n",
    "for label, n_classes in CELEBA_MULTI_LABELS.items():\n",
    "    uniform_distrib = [1/n_classes for i in range(n_classes)]\n",
    "\n",
    "    uniform_tensor = torch.tensor(uniform_distrib).unsqueeze(0)\n",
    "\n",
    "    prior.append(torch.distributions.categorical.Categorical(probs= uniform_tensor))\n",
    "    dict_index_class[i] = label\n",
    "    i+=1\n",
    "\n",
    "dict_class_index = {v:k for k,v in dict_index_class.items()}\n",
    "prior[0].probs[0][0] # First categorical distribution, row 1 (always), n_classes probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how we compute it in the \\_\\_init\\_\\_function of the *multiclass_dataset_cached.py* file. In accordance with the original method, we compute the empiric probability of appearance of a given class for a given label in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5, 0.5], [0.25, 0.75], [0.25, 0.5]]\n",
      "tensor([[0.5000, 0.5000]])\n",
      "tensor([[0.2500, 0.7500]])\n",
      "tensor([[0.3333, 0.6667]])\n"
     ]
    }
   ],
   "source": [
    "# Toy dataset\n",
    "tensor = torch.tensor([\n",
    "    [0, 1, 2],\n",
    "    [1, 1, 1],\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Toy dict, index:nb_classes\n",
    "dict_test = {0: 2, 1:2, 2:2}\n",
    "\n",
    "probs_prior = []\n",
    "data_size = tensor.shape[0] # Dataset size\n",
    "for lab_idx, nclass in dict_test.items():\n",
    "    # computing probs_prior for label lab_idx\n",
    "    probs_lab = [] \n",
    "    for j in range(nclass):\n",
    "        probs_lab.append(torch.sum(tensor[:, lab_idx] == j).item()/data_size) # Counting the nb of appearances of each class, divided by total samples\n",
    "    probs_prior.append(probs_lab)\n",
    "\n",
    "print(probs_prior)\n",
    "prior = [torch.distributions.categorical.Categorical(probs= torch.tensor(lab_prior).unsqueeze(0)) for lab_prior in probs_prior]\n",
    "for p in prior:\n",
    "    print(p.probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_load_csv function **COPY THIS**:\n",
    "```\n",
    "def _load_csv(\n",
    "    self,\n",
    "    filename: str,\n",
    "    header: Optional[int] = None,\n",
    ") -> CSV:\n",
    "    with open(os.path.join(self.root, self.base_folder, filename)) as csv_file:\n",
    "        data = list(csv.reader(csv_file, delimiter=\" \", skipinitialspace=True))\n",
    "\n",
    "    if header is not None:\n",
    "        headers = data[header]\n",
    "        data = data[header + 1 :]\n",
    "    else:\n",
    "        headers = []\n",
    "\n",
    "    indices = [row[0] for row in data]\n",
    "    data = [row[1:] for row in data]\n",
    "    # Delete rows with nans\n",
    "    indices_int = []\n",
    "    data_int = []\n",
    "    for i, row in enumerate(data):\n",
    "        try:\n",
    "            data_int.append(list(map(int,map(float,row))))\n",
    "            indices_int.append(indices[i])\n",
    "        except Exception as e:\n",
    "            pass # If error (nan), we discard the row\n",
    "\n",
    "    return CSV(headers, indices_int, torch.tensor(data_int))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is slightly modified to work in here, but is an exemple of the how the modifed function work\n",
    "CSV = namedtuple(\"CSV\", [\"header\", \"index\", \"data\"])\n",
    "\n",
    "def load_csv(path,\n",
    "    header: Optional[int] = None,\n",
    ") -> CSV:\n",
    "    with open(path) as csv_file:\n",
    "        data = list(csv.reader(csv_file, delimiter=\" \", skipinitialspace=True))\n",
    "\n",
    "    if header is not None:\n",
    "        headers = data[header]\n",
    "        data = data[header + 1 :]\n",
    "    else:\n",
    "        headers = []\n",
    "    # Remove lines containing NaN\n",
    "    indices = [row[0] for row in data]\n",
    "    data = [row[1:] for row in data]\n",
    "    indices_int = []\n",
    "    data_int = []\n",
    "    for i, row in enumerate(data):\n",
    "        try:\n",
    "            data_int.append(list(map(int,map(float,row))))\n",
    "            indices_int.append(indices[i])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return CSV(headers, indices_int, torch.tensor(data_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of all dataset: 202599\n",
    "\n",
    "Size of data set without Nan: 124892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202599"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with originial dataset to see if sthg has changed\n",
    "csv_attr = load_csv(\"./data/datasets/celeba/celeba/list_attr_celeba.txt\", header=1)\n",
    "len(csv_attr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124892"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with multiclass dataset to see if size is correct\n",
    "csv_attr = load_csv(\"./data/datasets/celeba/celeba/list_attr_multiclass_celeba.txt\", header=1)\n",
    "len(csv_attr[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the multiclass dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MULTI_CLASS dataset\n",
      "Splitting Dataset\n",
      "Loading MULTI_CLASS dataset\n",
      "Loading MULTI_CLASS dataset\n"
     ]
    }
   ],
   "source": [
    "loaders = mdc.setup_data_loaders(False, 1, root=\"./data/datasets/celeba\", download=False, multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sup': <torch.utils.data.dataloader.DataLoader at 0x7fd2058880a0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7fd1e8b6baf0>,\n",
       " 'valid': <torch.utils.data.dataloader.DataLoader at 0x7fd1c85ed040>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datastet Name sup\n",
      "Characteristics Dataset CELEBACached\n",
      "    Number of datapoints: 80247\n",
      "    Root location: ./data/datasets/celeba\n",
      "    Target type: ['attr']\n",
      "    Split: train\n",
      "Elements of dataset are <class 'tuple'> of shape 2:\n",
      "\tElt 1 is a <class 'torch.Tensor'> of shape torch.Size([3, 64, 64])\n",
      "\tElt 2 is a <class 'torch.Tensor'> of shape torch.Size([1])\n",
      "\n",
      "Datastet Name test\n",
      "Characteristics Dataset CELEBACached\n",
      "    Number of datapoints: 12186\n",
      "    Root location: ./data/datasets/celeba\n",
      "    Target type: ['attr']\n",
      "    Split: test\n",
      "Elements of dataset are <class 'tuple'> of shape 2:\n",
      "\tElt 1 is a <class 'torch.Tensor'> of shape torch.Size([3, 64, 64])\n",
      "\tElt 2 is a <class 'torch.Tensor'> of shape torch.Size([1])\n",
      "\n",
      "Datastet Name valid\n",
      "Characteristics Dataset CELEBACached\n",
      "    Number of datapoints: 20000\n",
      "    Root location: ./data/datasets/celeba\n",
      "    Target type: ['attr']\n",
      "    Split: train\n",
      "Elements of dataset are <class 'tuple'> of shape 2:\n",
      "\tElt 1 is a <class 'torch.Tensor'> of shape torch.Size([3, 64, 64])\n",
      "\tElt 2 is a <class 'torch.Tensor'> of shape torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for l in loaders:\n",
    "    dataloader = loaders[l]\n",
    "    print(f'\\nDatastet Name {l}')\n",
    "    print(f'Characteristics {dataloader.dataset}')\n",
    "\n",
    "    print(f'Elements of dataset are {type(dataloader.dataset[0])} of shape {len(dataloader.dataset[0])}:')\n",
    "    print(f'\\tElt 1 is a {type(dataloader.dataset[0][0])} of shape {(dataloader.dataset[0][0]).shape}')\n",
    "    print(f'\\tElt 2 is a {type(dataloader.dataset[0][1])} of shape {(dataloader.dataset[0][1]).shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we get almost the same loaders when using multi-class, but there are some slight differences:\n",
    "- The tensors in the dataset will be of the size of `CELEBA_MULTI_LABELS` (against 18 for the original `CELEBA_EASY_LABELS`). **Be sure to add the labels you want to train on in this dictionary. WARNING: the hair-colour labels have been erased for multi-class (united in a *Hair_MULTI* label)**\n",
    "- The prior function is no more a `tensor((1, n_labels), dtype=float)` but a **list of categorical distributions L**. For one multi-class label, the prior can be accessed with `L[label_idx].probs[0]` (because the probs object is itself a tensor of size $(1, n_{classes})$, so we get the column). In a way, this architecture is agnostic. The binary labels will also have a categorical distribution with 2 classes, that is, a Bernoulli distribution.\n",
    "\n",
    "When dealing with mutli-class labels, use the `setup_data_loaders` function of the *multilabel_dataset_cached.py* file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nteract": {
   "version": "0.28.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1c71177af1022ff567de0cfeeb71ca71839ef28bbdcefc10e5dd9d97d7b358e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
